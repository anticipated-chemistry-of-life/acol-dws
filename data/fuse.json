{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Anticipated Chemistry of Life","n":0.5},"1":{"v":"\n# Welcome to the Dendron of the Anticipated Chemistry of Life\n\nThis dendron has the purpose to serve as a laboratory notebook for my PhD thesis. It will contain all the notes that I will take during my research as well as some results of the experiments and models that I will develop and test.\n","n":0.136}}},{"i":2,"$":{"0":{"v":"Open Notebook","n":0.707}}},{"i":3,"$":{"0":{"v":"2025","n":1}}},{"i":4,"$":{"0":{"v":"08","n":1}}},{"i":5,"$":{"0":{"v":"2025-08-week-2","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.08.14\n\n##Â Meeting with Dan\n### Mass spec data\n\nGiven that we have mass spec gym, we can estimate the distribution of the score given \n\nFor the truth dataset\n1. Run $k$ methods of choice for true molecules\n2. get the distribution of scores for the true molecule for each method $k$\n3. choose 255 bins to represent that distribution\n4. Determine the likelihood for each bin\n\n#### To Do\nPlay around with the scores of the different annotations tools to see if we can reduce the number of times the true molecule actually\na score of $0.0$.\n\n### Speed of insertion Y vector\n","n":0.101}}},{"i":6,"$":{"0":{"v":"07","n":1}}},{"i":7,"$":{"0":{"v":"2025-07-week-3","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.07.25\n\n\n## QCxMS2\nQCxMS2 is a tool to simulate mass spectra given a SMILES. This approach uses quantum chemistry calculations. \nI'd like to test it out to see how well the results are. However, the calculations are really heavy. \n\nI've been testing it out with the first molecule in MassSpecGym but am getting sometimes pretty good results and sometimes not.\nI still need to tune a bit the parameters to see what works.\n\n## EMI-Monorepo\nWent back to the monorepo with Luca. Currently, creating a crate that generates mermaid graphs automatically. This \nallows us to visualize better the structure of the database. \n\n## Random Markov Field\nAs Dan said I should create a standard way to plot all the annotation tools tested (MetFrag, CFM-ID, Sirius). \n\nTurns out that Sirius is good for getting top 1 results but is the worst to find the total number of results. It tested by giving \nall the spectra present in MassSpecGym to Sirius and it ignored about half of them. \n\n### TODO\nCurrently the update of Y is really slow if we start to have many nodes in our tree. What I would like to do is to\nchange the code so that only if all threads ask for an update of the sheet, then the sheet will be updated. Currently we are not \ndoing this. What we do is that we parallelize on the last internal loop. But that one is already quite fast so there might be a lot of overhead \nof the threads by doing so. \n\nWhat I want is to check if all threads are true, then do and update. \n\nTo use :  `std::all_of` and `omp barrier` ?\n","n":0.06}}},{"i":8,"$":{"0":{"v":"06","n":1}}},{"i":9,"$":{"0":{"v":"Week 1","n":0.707},"1":{"v":"\n# Recap Week 1 of June 2025\n\n## ICEBERG\nI tested the quality of the ICEBERG model using MassSpecGym. The model isn't very good. It also has the problem that their modern model is closed source, so we can't use. \nI would like to train this model using the MassSpecGym dataset. I don't now if I should adapt MassSpecGym to how the data is stored in ICEBERG or if I should rewrite the ICEBERG model. \n\n## Meeting with Dan and Pierre-Marie\n- We discussed how I should change a bit the model for the species and molecules papers. \n- How we will handle mass spectrometry data for the model.\n\n### Paper counts\nThe model should take as input not only the pair of species-molecules but also a separate file with the counts per species and molecule.","n":0.087}}},{"i":10,"$":{"0":{"v":"03","n":1}}},{"i":11,"$":{"0":{"v":"Week 3","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.03.21\n\n\n# Week 3 of March 2025\n\n## Markov Random Field\nThis week I mainly worked on the Markov Random Field with Madleina. We were able to debug the simulations and ran the first simulations.\n\n### Model validation\nTo validate our model, we created specific trees. The molecules' tree is a tree containing only roots paired with a leaf. This creates pairs of nodes\nthat should be seen as repetitions of samples. We build the species tree in two different ways:\n- One tree had one root and only leaves.\n- The other tree was a balanced binary tree\n\nThe general idea was that the molecules' tree would contain no information by fixing the branch length of each branch to the same value.\nBy doing so, we would be able to approximate the rate matrix $\\Lambda_c$ by summing the number of times a node was 0 given that the root was 0, \na node was a 1 given that the root was 0, etc... \nFor more details see this specific [section](./random-markov-field.model-validation.md).\n\n### Inference validation\nThe next step is to debug inference and see if we are capable of inferring something from the simulated data.\n\n- Simulate a simple tree, by using the same $\\mu$ and branch length for all $\\rightarrow$ infer Y or Z and check if they match the true value.\n- Read y and Z, fix them and see if we can infer mu and the branch length.","n":0.066}}},{"i":12,"$":{"0":{"v":"02","n":1}}},{"i":13,"$":{"0":{"v":"Week 3","n":0.707},"1":{"v":"\n# Week 3\n## Markov Random Field\nThis week we continued the development of the MRF with Madleina. \n\n### Milestone\nWe implemented all the updates of the paramenters of the model. Next week we are going to put all the pieces together and run the first simulation.\n\n## Monorepo\nCalled Luca to discuss about the postgres extension for the weather data. Will try to start the extension next week.\n\n## Misc\n- Dove into Sirius to understand better how the program works. Turns out their approach is quite robust. \n- I tried different models to go from MS2 spectra to molecules. I first started with small text generation models but there is not enough data.\n- I then thought about splitting the problem in two parts : 1. predict the molecular fingerprint and 2. predict the molecule from the fingerprint. Turns out this exactly what Sirius does (along with MSNovelist).\n- Currently testing out MassSpecGym to see if I can train small models to extract molecular fingerprints from mass spec. I am using MS2DeepScore to embed the MS2 spectra.\n","n":0.077}}},{"i":14,"$":{"0":{"v":"Week 1","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.02.07\n\n\n## Events of this week\n### Markov Random Field\nContinued creating the functions to simulate data to test the model. Simulations for Lotus are \ndone, I also have done the simulations for the $\\mu$ in the cliques. I also added \nsimulations for Z now. \n\nWe are missing the sampling of Y. I will need to ask Madleina next week how to do this. This \npart is taking a bit more time that expected. I hope we can run some simulations maybe at the end of next week.\n\n### Bachelor students\nI looked into the dataset we are going to buy for the students. There were a couple of mistakes in \nthe excel sheet that was sent to me.\n\n### EMI Monorepo\nContinued a bit on the monrepo. Will have to create the tables for the weather data.\n\n\n","n":0.085}}},{"i":15,"$":{"0":{"v":"2025-02-10","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.02.10\n\n## Meeting PMA and Bachelor Students\nThey should start in two weeks i.e. the 3rd March 2025. \n\n1. we need the infrastructure to collect samples in the JB. However mass spec is down, and QField is not setup\nso the best would be to have the monorepo up and running.\n2. In the wait, we start with the fake extract. --> Data cleaning of Compactus, calculate logP, NP score, etc. \n   1. Create github account\n   2. add to the different organizations\n   3. Setup dendron (often a mess...) \n   4. Create blank repo for datacleaning of Compactus.\n\n### Fake extract\n\n\n## Notes\n\n\n## Todo today\n- [ ] \n\n## Doing\n\n\n## Done\n*  \n\n\n## Todo tomorrow\n- [ ]","n":0.093}}},{"i":16,"$":{"0":{"v":"2025-02-04","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.02.04\n\n\n## Notes\n### Call with Madleina\nTo do simulations : \n- Draw branch length \n- Draw the mus\n- In the `void TMarkovField::_simulateUnderPrior(Storage *)` function, we need to first draw the roots based on the \n\nFor each tree, go over all cliques, and for each clique, draw a value for the root just from the stationary distribution. \nThen go over all internal nodes and draw the values based from transition probabilites. If it is a one, we store it in the Z of the tree. \nThen we have Z. \n\nThen we simulate the Y. In order to draw a Y we need the cliques in all dimensions. Naive approach: loop over all Ys.\nFor each Y get all cliques of that Y. Calculate the probability of leaf=1 for each leaf representing that Y given the parent the of that\nleaf. Multiply all those probabilities and draw a value form that product of probabilites. If the value drawn is a one, we store it in a Y.\n\nThen this Y can be used to simulate a Lotus data (this function has already been written). \n\n![](assets/images/20250204_141828.png)","n":0.074}}},{"i":17,"$":{"0":{"v":"01","n":1}}},{"i":18,"$":{"0":{"v":"Week 3","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2025.01.24\n\n# Updates from January\n## Markov Random Field\nWith Madleina we continued working on the MRF. We are still working on the update of Y. This part is tricky\nbecause the elements of Y vector are not independent for each dimension. We had to come up\nwith a couple of tricks to make it work. Right now it is difficult to create unit tests \nand we might test the model directly with simulations.\n\n![](assets/images/20250122_145406.jpg)\n\n## Sirius database\nThis was a simple and quick thing to do. Pascal Pamrein created a database of in-silico reactions\nof molecules in LOTUS with some enzymes-SMARTS. This created a database of about 3 million compounds.\nI converted this database into a database for Sirius 6. We now hope that some of those \"synthetic\" molecules\nwill be present in future mass spec runs. \n\n## Cleaning LOTUS\nCurrently trying to find different ways of cleaning up lotus. I have added a filter for single atoms, \ndouble atoms, and NP-score likeness. This filters about 4% if the compounds.\n\n## Species-hammer\nSince LOTUS is highly biased, Luca told me to parse Pubmed in search of occurences of the molecules in lotus\nand then use this information as a heuristic to estimate the presence of the molecules across the tree of life. \nSo far, we have very little data so the output of Hammer will probably be quite bad. \n\n## Bachelor students\nIn order for the bachelor students to start nicely in February, I have to prepare some material for them: \n- I have to look into the molecules availble in the lab to see if we can create our own fake extract.\n- I have to look at the different availble NP libraries to see if we there are some more or less cheap ones that we can use.\n- I need to continue working on the Monorepo because it would be nice to have a working version for them \nto use so that they can go sample plants using the app.\n","n":0.056}}},{"i":19,"$":{"0":{"v":"2024","n":1}}},{"i":20,"$":{"0":{"v":"12","n":1}}},{"i":21,"$":{"0":{"v":"Week 1","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\n## Events of this week\nLast week we discussed with Daniel, Pierre-Marie and Madleina about the mass spectrometry part on the Markov Random Field model. We concluded that we need a way to compare MS2 spectra with each other. To do so we will be generating MS2 spectra from smiles strings using CFM-ID 4.0. Pascal Pamrein had to generate a set of new molecules starting from the Lotus database. I am currently running CFM-ID on the set of those molecules.\n\nAlso I started working of a comparator between simulated spectra and real spectra. I hope that CFM-ID is good enough to generate MS2 spectra that are similar to the real ones. The idea would then to use those simulated spectra to compare them with the real ones. We could then generate huge sets of simulated spectra and if we have good matches with real ones, we know that those molecules are similar. \n\nTo do so, I am sampling molecules present in ISDB and checking of they are present in GNPS. In GNPS since it is experimental data, it is possible to have the same molecule with different MS2 spectra. On the other hand, ISDB is a database of in-silico spectra. This means that a smiles will always have the same MS2 spectra (if we are using CFM-ID). My plan is to see if a molecule is present in both databases and if it is, I want to calculate their similarity based on different metrics. I am also sampling some molecules randomly to see if the similar molecules actually produce similar scores.\n\nFinally I continued working on the EMI portal with help of Luca. We are currently working on the Webcodegen crate to automatically generate code. ","n":0.059}}},{"i":22,"$":{"0":{"v":"11","n":1}}},{"i":23,"$":{"0":{"v":"Week 3","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\n## Events of this week\n- Continued advance Random Markov Field model. Struggled with debugging the code and checking that the update of $Z$ is done correctly. \n- Created the poster for the Bachelor students. ","n":0.16}}},{"i":24,"$":{"0":{"v":"Week 2","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\n## Events of this week\n- Luca came to Fribourg. He showed me how we are goind to reimplement the python code generation packages to the \n`syn` crate. This allows us to generate syntax compliant code for Rust and we can do actual type checking.\n- I will need to dive with Luca into his \"Hammer\" package as it can be useful for my thesis.\n- I worked a bit on the metaprogramming part of the monorepo.\n\n- Meeting on Wednesday about the DBGI wrapup. We discussed what everyone did during the two years project. \n","n":0.102}}},{"i":25,"$":{"0":{"v":"Week 1","n":0.707},"1":{"v":"\n## This week I have\nContinued working on the Markov Random Field. I have been working on the implementation of a smart binary\nsearch to make it even faster than it already is. \n\nLuca explained to me that the GCN that he developped doesn't need a DAG of the same depth as output but can take any graph\nas input. ","n":0.132}}},{"i":26,"$":{"0":{"v":"2024-11-28","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.11.28\n\n\n## Notes\n### Meeting with Daniel Probst. \nGoal: library more *modular* than RDKit. RDKit is a big lib and if you want to parse a single smiles,\nyou have to load the whole library.\n\nSwitch to more functional programming. No quantum calculations or force fields. Not only work with small molecules\nbut also with proteins and allow for pdb files.\n\nMarvin Sakler works at Microsoft and might join the link.\n\n## Todo today\n- [ ] \n\n## Doing\n\n\n## Done\n*  \n\n\n## Todo tomorrow\n- [ ]","n":0.109}}},{"i":27,"$":{"0":{"v":"10","n":1}}},{"i":28,"$":{"0":{"v":"2024-10-summary","n":1},"1":{"v":"\n# Summary of October 2024\n\n## Start of the thesis\n\n## Random Markov Field\nWe started the implementation of the random markov field. The main discussion\nwas how can we store all the data- that we need in a reasonable amount of memory. To do so we decided\nto use a uint64 vecore to store the data where each bit represents a different value of the class. \nThe first 16 bits are used to store the counter of the MCMC, for counting how many times our combination\n(species-molecule) was a 1. The 17th bit is to store the actual state of the combination (if it is 1 or 0).\nThe next 47 bits are used as index of the combination in the molecule and species vectors.\n\nWe are now discussing if a vector is the best way to store the data or if we should use a hashmap\n(`std::unordered_map`).\nIt seems like a vector with a \"hinted\" binary search could lead to extremely fast access to the data.\n\n### Z dimension\nFor the Z dimension of the model, since we don't need to store the counter, we decided to go with a int32 where the \nvalue is the coordinate of the vector and the sign is the state of the combination.\n\n## MS2 compound or compound to MS2\nLuca has been working on different models to predict the classification of a molecule. He has also \nbeen working on the classification of MS2 spectra to chemical classifications. We would ideally try to develop\na model that can predict a smiles or a chemical fingerprint given a MS2 spectrum.\n\n## RDKit Rust\nI am also working from time to time to create a binding beween C++ and Rust for the RDKit library. I am \na bit in contact with the creators of the crate but they are not very responsive. MAybe I should \nfully develop my own fork.  \n\n","n":0.058}}},{"i":29,"$":{"0":{"v":"2024-10-14","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.10.14\n\n## Meeting with Madleina\n- [ ] start by creatin a script that is able to fetch phylogeny from lotus and molecules\n- [ ] use Cache\n- [ ] for species, get full wikidata taxo, then remove all species with their parent that are not in lotus.\n- [ ] input should be a node and then it will get all the children of that node : Plantae --> all the children of plantae\n- [ ] use that to subset lotus\n\n## Notes\nThis is the qlever sparql query to get all the mammals and their parent taxa.\n\n```sparql\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX wd: <http://www.wikidata.org/entity/>\n\nSELECT ?taxon ?taxon_name ?taxon_rank ?taxon_rank_label ?taxon_parent ?parent_name WHERE {\n  ?taxon wdt:P225 ?taxon_name;\n         wdt:P105 ?taxon_rank;\n         wdt:P171* wd:Q7377;      # Recursively fetches all taxa with Mammal as an ancestor\n         wdt:P171 ?taxon_parent.\n\n  ?taxon_rank rdfs:label ?taxon_rank_label.\n  FILTER (lang(?taxon_rank_label) = \"en\")\n  FILTER (?taxon_rank != wd:Q68947)  # Exclude taxa with rank \"subspecies\"\n\n  ?taxon_parent wdt:P225 ?parent_name.\n}\n```\n\nThis is a nice query because we can then create a function that will fetch all the children of a node. We will use the Mammal for testing our model as they are not too many. \n\nWhat I need to do then is to create a function that given a root node, will return all the children (with the option of filtering the sub-species). It should also be able to not rerun the full function if the query and the output of that query is already in the cache.\n\nThis query : \n```sparql\nPREFIX wdt: <http://www.wikidata.org/prop/direct/>\nPREFIX p: <http://www.wikidata.org/prop/>\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\nPREFIX pr: <http://www.wikidata.org/prop/reference/>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX wd: <http://www.wikidata.org/entity/>\n\nPREFIX prov: <http://www.w3.org/ns/prov#>\nSELECT DISTINCT ?structure ?structure_inchikey ?taxon ?taxon_name ?reference ?reference_doi ?taxon_rank ?taxon_rank_label ?taxon_parent ?parent_name WHERE {\n  ?structure wdt:P235 ?structure_inchikey;  # get the inchikey\n    p:P703 ?taxon_statement.                # find the statement node\n  \n  ?taxon_statement ps:P703 ?taxon.          # get the taxon from the statement node\n  ?taxon_statement prov:wasDerivedFrom ?ref_node. # get the reference node from the statement node\n  ?ref_node pr:P248 ?reference.             # get the reference item\n\n  ?taxon wdt:P225 ?taxon_name;              # get the taxon scientific name\n         wdt:P105 ?taxon_rank;              # get the taxon rank\n         wdt:P171* wd:Q21730;                # recursively fetch all taxa with Asterales as an ancestor\n         wdt:P171 ?taxon_parent.            # get the taxon's immediate parent\n\n  ?taxon_rank rdfs:label ?taxon_rank_label.\n  FILTER (lang(?taxon_rank_label) = \"en\")\n  FILTER (?taxon_rank != wd:Q68947)         # exclude taxa with rank \"subspecies\"\n\n  ?taxon_parent wdt:P225 ?parent_name.      # get the parent taxon's scientific name\n  ?reference wdt:P356 ?reference_doi.       # get the reference DOI\n}\n```\nWill get all the molecules that are associated with any taxon that is a child of Asterales. This is also very useful to quickly get all the molecules associated with a taxon.\n\n\n## Todo today\n- [ ] \n\n## Doing\n\n\n## Done\n*  \n\n\n## Todo tomorrow\n- [ ]","n":0.048}}},{"i":30,"$":{"0":{"v":"2024-10-10","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.10.10\n\n## Meeting with Madleina\n\n\n\n## Notes\n\n\n## Todo today\n- [ ] \n\n## Doing\n\n\n## Done\n*  \n\n\n## Todo tomorrow\n- [ ]","n":0.204}}},{"i":31,"$":{"0":{"v":"2024-10-01","n":1},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is 2024.10.01\n\n## First day of PhD\n\n\n## Notes\n\n\n## Todo today\n- [ ] start presentation for 10th of October\n- [ ] organise meeting with Daniel, Madleina and PMA\n- [ ] Contact Luca for HyperSketching availability (and see potential approaches to include MS data in the project)\n- [ ] Recap on what has been done so far\n- [ ] Do a little of litterature review\n\n## Doing\n\n\n## Done\n*  Talk with PMA\n*  setup computer and keyboards\n\n\n\n## Todo tomorrow\n- [ ]","n":0.111}}},{"i":32,"$":{"0":{"v":"Templates","n":1}}},{"i":33,"$":{"0":{"v":"Open Notebook","n":0.707},"1":{"v":"# This is Marco's daily open-notebook.\n\nToday is {{ CURRENT_YEAR }}.{{ CURRENT_MONTH }}.{{ CURRENT_DAY }}\n\n\n## Notes\n\n\n## Todo today\n- [ ] \n\n## Doing\n\n\n## Done\n*  \n\n\n## Todo tomorrow\n- [ ]","n":0.192}}},{"i":34,"$":{"0":{"v":"Seminars","n":1}}},{"i":35,"$":{"0":{"v":"Communication in Science","n":0.577},"1":{"v":"\n# Who\n\nWho are you communicating to?\n\n# Why\n\n# What\n\nWhat do you want to say?\n\n# How\nOnion technique\n\n## Oral presentation\n- PowerPoint or not ?\n- 1 slide per minute (if you have 10 minutes, create 10 slides and then dispatch these 10 slides according to what you want to say)\n- make a template\n- do not overfill\n- images help\n- Microphone (if you have big room, accept microphone)\n\nLook at the audience, be authentic (**be yourself**), talk slow, use the space you have, prepare for tech issues, visualization\n\n## Social media communication\n- Platform specific\n- Consistency\n- Keep it short\n- Prepare for pushback\n- for video content, prioritize good audio, speak faster than you think","n":0.098}}},{"i":36,"$":{"0":{"v":"Random Markov Field","n":0.577}}},{"i":37,"$":{"0":{"v":"Ideas","n":1}}},{"i":38,"$":{"0":{"v":"Mass Spectrometry","n":0.707},"1":{"v":"\n# How should we include mass spectrometry in our random Markov field ?\n\nOn the 17th June 2025 we discussed with Dan and PMA some ideas on how we will implement the mass spec data in our model.\nGiven that the LOTUS data is not sufficient to make predictions of occurrences, we need to take mass spec into account.\n\nThe idea is that during the MCMC, the model will propose a set of molecules (a vector of $0$ and $1$) and compare it\nwith the data. Then we accept or reject this proposal so on (classic Gibbs sampling and MCMC).\n\nWe thought there are two main approaches to the problem.\n\n## Use post-annotation data\nThis would include using MZMine/Sirius annotation pipelines to then have a list of molecules detected in a sample. \n\n#### Pros\nComparison is easy between the proposal vector and the data\n\n#### Cons\nWe rely on other tools that may output wrongly annotated data.\n\n## Use mass spec data directly\nThere are many ways we could use mass spec data\n\n### Artificial spectra\nWe could simulate a mass spectrum given a SMILES and compare it to a mass spec run. For\neach molecule that we have, we could have a similarity score to the closest spectrum in \nthe MS run.\n![](./assets/images/IMG_20250619_134804_1.jpg)\n\n\n#### Pros\n- There are many tools to simulate a mass spectrum\n- There are many tools to calculate the similarity between two spectrums (Cosine, Dreams embedding, Entropy, etc...)\n\n#### Cons\n- The simulation tools are not very good due to the lack of training data.\nThis would result in having some molecules with low probability even-though they are truly there (see ICEBERG-evaluation).\n\n### MS1\nAn idea that came to mind was to directly use the MS1 scans of a mass spectrum. This allows to \ndirectly use the high resolution of the machine. The idea is the following: \n\nFor each molecule in LOTUS, calculate its mass with hydrogen adduct. Then calculate the isotopic pattern\nof that molecule. Then check if the two masses are present in the MS run. \n\n#### Pros\n- Use the resolution of mass spec\n- Can match to molecules that might not even have an MS2 spectrum (due to Top-N DDA).\n\n#### Cons\n- We can only work with **molecular formulas**\n- Probably high false positives rate\n- Strongly depends on adduct selection\n\n![](./assets/images/IMG_20250619_134816.jpg)\n\n## Questions for PMA : \n- How do we infer the adduct when we have only a mass ?\n- Should we benchmark MetFrag ? Can we use MetFrag to benchmark LOTUS-MINES","n":0.051}}},{"i":39,"$":{"0":{"v":"Computational Tricks","n":0.707},"1":{"v":"\n## Computational tricks \n### Discretization of branch lengths\nThe parameters of the rate matrix $\\mu_{c1}$ and $\\mu_{c2}$ and the branch lengths $b(n)$ are non identifiable: doubling all rate parameters and halving all branch lengths will lead to the exact same solution. We therefore introduce the constraint: \n\n$$\n\\sum_n{b(n)} = 1\n$$\n\nsuch that  $0 \\leq b(n) \\leq 1$  for all branch lengths $b(n)$. We further note that calculating the matrix exponential $\\mathbf{P}(n) = \\exp(\\mathbf{\\Lambda_c}b(n))$  for every possible\nbranch length is computationally prohibitive. To reduce the number of calculations, we bin the\nbranch lengths to predefined values. Specifically, let there be a regularly spaced grid on the\ninterval $[a, b]$ consisting of $K$ bins. The width of each bin is given by $\\Delta = \\frac{b-a}{K}$ Let us further define by $k(n) \\in 0,..., K-1$ the bin the bin where node $n$ is assigned to. The transition matrix of the first three bins is given by:\n\n$$\n\\begin{align}\n\\mathbf{P}(0) &= \\exp(\\mathbf{\\Lambda_c}a) \\\\\n\\mathbf{P}(1) &= \\exp(\\mathbf{\\Lambda_c}(a + \\Delta)) \\\\\n\\mathbf{P}(2) &= \\exp(\\mathbf{\\Lambda_c}(a + 2\\Delta)) \\\\\n\\end{align}\n$$\n\nMore generally, the transition matrix for bin $k$ is given by: \n$$\n\\mathbf{P}(k) = \\exp(\\mathbf{\\Lambda_c}(a + k\\Delta))\n$$\n\nFor all $k = 1,..., K-1$,  this term can be calculated efficiently using a recursion:\n\n$$\n\\begin{align}\n\\mathbf{P}(k) &= \\exp(\\mathbf{\\Lambda_c}(a + k\\Delta)) \\\\\n&= \\exp(\\mathbf{\\Lambda_c}(a+(k-1)\\Delta) + \\Lambda_c\\Delta) \\\\\n&= \\exp(\\mathbf{\\Lambda_c}(a+(k-1)\\Delta))\\exp(\\Lambda_c\\Delta) \\\\\n\\end{align}\n$$\n\nwhere $\\exp(\\mathbf{\\Lambda_c}(a+(k-1)\\Delta))$  corresponds to the transition matrix of the previous bin $k-1$, and $\\mathbf{\\alpha} = \\exp(\\Lambda_c\\Delta)$ is a scaling matrix that needs to be calculated once. Therefore, the matrix exponential needs to be calculated only twice: once for calculating first transition matrix $\\mathbf{P}(0)$ and once for calculating the scaling matrix $\\mathbf{\\alpha}$. The transition matrices of all subsequent bins are obtained by a recursive matrix multiplication, which is very cheap to calculate.\nSince the sum of all branch lengths is constrained to one, most branch lengths will likely be very small. We therefore set $a = 0$ and $b = 0.1$  by default, assuming that the longest branch length of the tree will not exceed 10% of the total length. We further set $K=100$ bins by default. However, all default values can be changed by the user. To respect the sum-one-constraint, we update the branch lengths in pairs. Specifically, we select two nodes $n_1$ and $n_2$ pick a sign (+ or -) and propose moving to an adjacent bin: either $k(n_1)' = k(n_1) + 1$ and $k(n_2)' = k(n_2) - 1$ or $k(n_1)' = k(n_1) - 1$ and $k(n_2)' = k(n_2) + 1$. If the bin of a node corresponds to the first or the last bin, $k(n) = 0$ or $k(n) = K-1$, there is only one possible direction for proposing. \n\n### Discretization of rate parameters\nWhen updating the transition rate parameters $\\mu_{c1}$ and $\\mu_{c2}$ for a clique $c$, the transition matrix $\\mathbf{P}(k)$ for all $k = 0,..., K-1$ bins must be re-calculated. Despite the above approach, this becomes computationally prohibitive when considering there to be millions of cliques  (one per molecule). We therefore propose to discretize the values of the rate parameters as well. We will use a regularlly spaced grid in the interval $[x,y]$ with a total of $M$ bins. It is **still not clear how many bins we will need**. It is then possible to pre-calculate and store all combinations of K branch lengths and $M^2$ values of $\\mu_{c1}$ and $\\mu_{c2}$, such that the update of these parameters will be very fast.","n":0.043}}},{"i":40,"$":{"0":{"v":"Branch Lengths","n":0.707},"1":{"v":"\n## Changes in the branch lengths binning\nPreviously we had that the total sum of the branch length was equal to 1. Now we have changed the binning so that the average branch length is equal to 1.\n\nWe define $m$ as the middle point of each bin so that we have $m_0$ the middle point of bin $0$. Now, the branch length of one has to be a middle point of the bins. We have as lower bound 0, and we want as many bins on the right side as on the left side of $1$.\n\n\nFor example, if we have 7 bins, we want to have 3.5 bins on the right side of 1 and 3.5 on the left side. We define $K$ as the number of bins on one side of 1 *i.e.* 3.5. $\\delta$ which is the interval of each bin is thus equal to \n\n$$\n\\delta = \\frac{1}{K+\\frac{1}{2}} = \\frac{2}{2K+1}\n$$\n\nif $K=\\frac{N}{2}$ and $N$ is the total number of bins we can simplify to \n\n$$\n\\delta = \\frac{2}{N+1}\n$$\n\nFor each bin $i$ where $i = (0, ..., N-1)$ the middle point $m_i$, the lower bound $l_i$ and the upper bound $u_i$ are equal to \n\n$$\n\\begin{align}\nm_i &= \\delta (i + \\frac{1}{2}) \\\\\nl_i &= \\delta i \\\\\nu_i &= \\delta (i+1)\\\\\n\\end{align}\n$$\n\n## Formulation\nAs previously, let us define $N$ the total number of bins and $B$ the total number of branch length in the tree. We want to constrain the tree in order to have an average branch length in the tree of 1.\n\nWe thus have \n\n$$\n\\frac{1}{B} \\sum_{b=0}^{B-1}{m_{i_{(b)}}} = 1\n$$\nAs defined before, $m_i = \\delta (i + \\frac{1}{2})$ and $\\delta = \\frac{2}{N+1}$ so we have \n\n$$\n\\begin{align}\n    1 &= \\frac{1}{B}\\sum_b \\delta(i_{b} + \\frac{1}{2}) \\\\\n    B &= \\sum_b \\delta (i_b + \\frac{1}{2}) \\\\\n    B &= \\frac{2}{N+1} \\sum_b (i_b+\\frac{1}{2}) \\\\\n    B \\frac{N+1}{2} &= \\sum_b i_b + \\frac{B}{2} \\\\\n    B (\\frac{N+1}{2} - \\frac{1}{2}) &= \\sum_b i_b \\\\\n    \\frac{BN}{2} &= \\sum_b i_b\n\\end{align}\n$$\n\n### Example\nIf we have $N=100$ and $B=50$, and let us set all branches to a length of 1 (in order to have an average of 1). Then the index of the bin where the branch length is one, is at 50. We thus have $\\frac{50 \\cdot 100}{2} = 2500$ and we have $50$ branches with a bin index of $50$ which is also equal to $2500$.","n":0.052}}},{"i":41,"$":{"0":{"v":"Examples","n":1}}},{"i":42,"$":{"0":{"v":"update-Z","n":1},"1":{"v":"\n\nWe created a couple of example to help us understand the update of $Z$ in the Random Markov Field model.\nWe realised we had problems in naming conventions so on the 27.11.2024 Madleina and I decided to refactor the \ncode base to make the varibale names more understandable and accurate to what we are trying to achieve.\n\n### $Z$ is specific to each dimension. \nWe will have one Z for each dimension.\n\nThe two images below show an example of the update of $Z$. \n\nWe see that the cross $\\times$ is part of the varibale dimension 1 wheter the star $*$ is part of the variable dimension 0. \n\nThe $Z$ for a specific dimension has as dimensions the number of internal nodes in the variable dimension and the number of leaves in all other dimensions. \n![](assets/images/20241127_153314.jpg)\n\n![](assets/images/20241127_103342.jpg)","n":0.087}}},{"i":43,"$":{"0":{"v":"Model Validation","n":0.707},"1":{"v":"\nToday is the 6th March 2025. With Madleina we finished the implementation of the MRF model are currently running a couple of simulations to see if the model is working as expected.\n\n### stattools DAG\nCurrently the model looks like this : \n![](./assets/images/20250303_142539.jpg)\n\n### Model validation\nTo validate the model we are going to create two fake trees. One tree will consist of pairs of nodes and roots that are independent of each other. We are also going to set all branch length to the same value. The rate parameters $\\mu_0$ and $\\mu_1$ are set to $0.5$. The other tree will consist of only one root with multiple leaves. We will then set all the branch length to same values and set the rate parameters to a arbitrary value. We will then run the model, and calculate the probability of going from the root to the node (for the second tree). This should result in the same values than the rate matrix.\n![](./assets/images/20250306_154257.jpg)\n\n\n\n## Questions\n- What is the 0 in `using TypeBinnedBranchLengths = coretools::UnsignedInt8WithMax<0>;` ? -> It is just some stattools internal thing. \n","n":0.075}}},{"i":44,"$":{"0":{"v":"Parameter Estimation","n":0.707},"1":{"v":"\nHere we test if the parameters of the model can be estimated given the data.\n\n\nThis was done in the [`single_root`](https://github.com/anticipated-chemistry-of-life/markov-random-field/tree/c15e5a1f1489f83610383347788aa063e8ccfede/model_validation/single_root) directory with the following parameters: \n\n```bash\n../../build/acol simulate \\\n    --tree_species species.txt \\\n    --tree_molecules molecules.txt \\\n    --num_iterations 100000 \\\n    --species_branch_lengths acol_input_simulated.txt \\\n    --species_var_log_nu acol_input_simulated.txt \\\n    --species_mean_log_nu acol_input_simulated.txt \\\n    --species_log_nu acol_input_simulated.txt \\\n    --species_alpha acol_input_simulated.txt \\\n    --molecules_branch_lengths acol_input_simulated.txt \\\n    --molecules_var_log_nu acol_input_simulated.txt \\\n    --molecules_mean_log_nu acol_input_simulated.txt \\\n    --molecules_log_nu acol_input_simulated.txt \\\n    --molecules_alpha acol_input_simulated.txt \\\n    --numThreads 1 \\\n    --write_Y \\\n    --write_Z \\\n    --write_joint_log_prob_density \\\n    --write_Y_trace \\\n    --write_Z_trace \\\n    --fixedSeed 456284939 \\\n```\n\n# Molecules\n## Molecules $\\alpha$\n![](./assets/images/20250328_molecules_alpha_2.png)\n![](./assets/images/20250328_molecules_alpha_12.png)\n\n![](./assets/images/20250328_molecules_branch_7.png)\n![](./assets/images/20250328_molecules_branch_35.png)\n\n![](./assets/images/20250328_molecules_log_nu_5.png)\n![](./assets/images/20250328_molecules_log_nu_12.png)\n\n![](./assets/images/20250328_molecules_Z.png)\n\n\n# Species\n![](./assets/images/20250328_species_alpha_1.png)\n![](./assets/images/20250328_species_alpha_32.png)\n\n![](./assets/images/20250328_species_branch_11.png)\n![](./assets/images/20250328_species_branch_12.png)\n\n![](./assets/images/20250328_species_log_nu_1.png)\n![](./assets/images/20250328_species_log_nu_36.png)\n\n![](./assets/images/20250328_species_Z.png)\n\n\n# And finally Y\n![](./assets/images/20250328_Y.png)","n":0.105}}},{"i":45,"$":{"0":{"v":"Debug","n":1},"1":{"v":"\n# A couple of notes on the current situation\n- We created a simple test case in python to check whether the current model works. We realized that our C++ implementation does not behave the same way as the python code. I am now currently trying to find the problem in the C++ code. \n\n- **Update of element at index 0**: we realized that there is a problem with the update of the first elements in the trace of Y (and maybe Z ?).\n\n## Single leaf for molecules\nSimilarly to the python code, I generated a star shaped tree for the species and a single root-leaf\npair for the species. \n\n","n":0.096}}},{"i":46,"$":{"0":{"v":"references","n":1},"1":{"v":"\n# References","n":0.707}}},{"i":47,"$":{"0":{"v":"Dendron","n":1},"1":{"v":"# Welcome to Dendron\n\nThis is a dendron vault.\n\n## Lookup\n\nThis section contains useful links to related resources.\n\n- [Getting Started Guide](https://link.dendron.so/6b25)\n- [Discord](https://link.dendron.so/6b23)\n- [Home Page](https://wiki.dendron.so/)\n- [Github](https://link.dendron.so/6b24)\n- [Developer Docs](https://docs.dendron.so/)","n":0.2}}}]}
